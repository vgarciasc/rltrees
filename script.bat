@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.001 -i 50 -e 100 --verbose True >> "log.txt"
@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.002 -i 50 -e 100 --verbose True >> "log.txt"
@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.003 -i 50 -e 100 --verbose True >> "log.txt"
@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.004 -i 50 -e 100 --verbose True >> "log.txt"
@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.005 -i 50 -e 100 --verbose True >> "log.txt"

@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-08 15-42_dagger_MountainCar-v0" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 16-09_dagger_MountainCar-v0" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 16-36_dagger_MountainCar-v0" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 16-40_dagger_MountainCar-v0" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 16-45_dagger_MountainCar-v0" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 16-50_dagger_MountainCar-v0" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"

@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 13-43_MountainCar-v0_bc_0.005" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 13-44_MountainCar-v0_bc_0.01" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 13-50_MountainCar-v0_bc_0.02" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-10 11-14_MountainCar-v0_bc_0.04" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t mountain_car -f "data/tree 2022-02-11 13-41_MountainCar-v0_bc_0" -o "data/mountaincar_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"

@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.000075 -i 50 -e 100 --episodes_to_evaluate 100 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.0001 -i 50 -e 100 --episodes_to_evaluate 100 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.0004 -i 50 -e 100 --episodes_to_evaluate 100 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.0006 -i 50 -e 100 --episodes_to_evaluate 100 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\dagger.py -t lunar_lander -f data/lunarlander_mlp -c KerasDNN -p 0.003 -i 50 -e 100 --episodes_to_evaluate 100 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"

@REM python imitation_learning\reward_pruning.py -t lunar_lander -f "data/tree 2022-02-14 22-22_dagger_LunarLander-v2" -o "data/lunarlander_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t lunar_lander -f "data/tree 2022-02-14 21-28_dagger_LunarLander-v2" -o "data/lunarlander_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t lunar_lander -f "data/tree 2022-02-14 20-15_dagger_LunarLander-v2" -o "data/lunarlander_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\reward_pruning.py -t lunar_lander -f "data/tree 2022-02-14 18-59_dagger_LunarLander-v2" -o "data/lunarlander_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"

@REM ECHO "Testando sem ruído, mas com dataset muito grande" >> "log.txt"
@REM python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.0 --should_collect_dataset True --dataset_size 10000 --expert_exploration_rate 0.00 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.005 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.01 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.02 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"
@REM python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.04 --verbose True >> "log.txt"
@REM ECHO -------------eof------------- >> "log.txt"

ECHO "Mountain Car: testando com ruído, e com dataset muito grande" >> "log.txt"
python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.0 --should_collect_dataset True --dataset_size 5000 --expert_exploration_rate 0.05 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"
python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.005 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"
python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.01 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"
python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.02 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"
python imitation_learning\behavioral_cloning.py -t mountain_car -f data/mountain_car_ann -c KerasDNN -p 0.04 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"

ECHO "Lunar Lander: testando com dataset muito grande, sem ruído" >> "log.txt"
python imitation_learning\behavioral_cloning.py -t lunar_lander -f data/lunarlander_mlp -c MLP -p 0.0 --should_collect_dataset True --dataset_size 5000 --expert_exploration_rate 0.00 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"
python imitation_learning\behavioral_cloning.py -t lunar_lander -f data/lunarlander_mlp -c MLP -p 0.00001 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"
python imitation_learning\behavioral_cloning.py -t lunar_lander -f data/lunarlander_mlp -c MLP -p 0.00005 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"
python imitation_learning\behavioral_cloning.py -t lunar_lander -f data/lunarlander_mlp -c MLP -p 0.0001 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"
python imitation_learning\behavioral_cloning.py -t lunar_lander -f data/lunarlander_mlp -c MLP -p 0.0003 --verbose True >> "log.txt"
ECHO -------------eof------------- >> "log.txt"

ECHO "Lunar Lander: vendo por que o reward pruning diminuiu a recompensa obtida pela árvore, quando o objetivo era manter" >> "log.txt"
python imitation_learning\reward_pruning.py -t lunar_lander -f "data/tree 2022-02-14 21-28_dagger_LunarLander-v2" -o "data/lunarlander_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 1 --max_pruning_iters 5 --grading_episodes 100 --should_plot True

ECHO "Lunar Lander: analisando a aleatoriedade do reward pruning " >> "log.txt"
python imitation_learning\reward_pruning.py -t lunar_lander -f "data/tree 2022-02-14 21-28_dagger_LunarLander-v2" -o "data/lunarlander_pruned" --comp_threshold 0.98 --episodes_per_prune 100 --pruning_cycles 5 --max_pruning_iters 5 --grading_episodes 100 >> "log.txt"